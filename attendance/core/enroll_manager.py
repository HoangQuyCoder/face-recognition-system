from datetime import datetime
import os
import pickle
import numpy as np
from core.insightface_singleton import InsightFaceSingleton


class EnrollManager:
    # ================= CONFIG =================
    MIN_CONFIDENCE = 0.60
    MIN_SAMPLE_SIMILARITY = 0.90  # 0.7
    MAX_OUTLIER_DISTANCE = 0.40
    # =========================================

    def __init__(self, db_path="database/embeddings.pkl", max_samples=15):
        self.db_path = db_path
        self.max_samples = max_samples
        self.samples = []           # list[np.ndarray]
        self.last_embedding = None
        self.app = InsightFaceSingleton.get_instance(
            name="buffalo_l",
            providers=["CPUExecutionProvider"],
            det_size=(320, 320),
            ctx_id=0
        )
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        print(f"‚úì EnrollManager ready")
        print(f"  - Max samples: {max_samples}")
        print(f"  - Similarity threshold: {self.MIN_SAMPLE_SIMILARITY}")
        print(f"  - Min confidence: {self.MIN_CONFIDENCE}")

    # =====================================================
    def add_frame(self, rgb_frame):
        """Th√™m frame v√†o danh s√°ch m·∫´u"""
        faces = self.app.get(rgb_frame)
        if len(faces) != 1:
            if len(faces) > 1:
                print(f"‚ö† Multiple faces detected ({len(faces)})")
            return False

        face = faces[0]
        if face.det_score < self.MIN_CONFIDENCE:
            print(
                f"‚ö† Low confidence: {face.det_score:.3f} < {self.MIN_CONFIDENCE}")
            return False

        emb = face.normed_embedding
        if emb is None:
            print("‚ö† No embedding extracted")
            return False

        # ===== Ch·ªëng sample tr√πng =====
        if self.last_embedding is not None:
            sim = float(np.dot(emb, self.last_embedding))
            if sim > self.MIN_SAMPLE_SIMILARITY:
                print(
                    f"‚ö† Too similar to last sample: {sim:.3f} > {self.MIN_SAMPLE_SIMILARITY}")
                return False
            print(f"‚úì Diversity OK: similarity={sim:.3f}")

        self.samples.append(emb)
        self.last_embedding = emb

        print(
            f"‚úÖ Sample #{len(self.samples)} added! ({len(self.samples)}/{self.max_samples})")
        return True

    # =====================================================
    def is_complete(self):
        """Ki·ªÉm tra ƒë√£ ƒë·ªß s·ªë l∆∞·ª£ng m·∫´u ch∆∞a"""
        complete = len(self.samples) >= self.max_samples
        if complete:
            print(
                f"üéâ Enrollment complete! {len(self.samples)}/{self.max_samples} samples collected")
        return complete

    # =====================================================
    def get_progress(self):
        """Tr·∫£ v·ªÅ ti·∫øn ƒë·ªô thu th·∫≠p (0.0 - 1.0)"""
        return len(self.samples) / self.max_samples

    # =====================================================
    def _remove_outliers(self, embeddings):
        """Lo·∫°i b·ªè c√°c embedding l·ªách kh·ªèi trung b√¨nh"""
        if len(embeddings) < 5:
            print(
                f"‚Ñπ Too few samples ({len(embeddings)}) to remove outliers, keeping all")
            return embeddings

        mean = np.mean(embeddings, axis=0)
        mean /= (np.linalg.norm(mean) + 1e-10)

        filtered = []
        removed_indices = []

        for i, emb in enumerate(embeddings):
            dist = 1.0 - float(np.dot(emb, mean))  # cosine distance
            if dist <= self.MAX_OUTLIER_DISTANCE:
                filtered.append(emb)
            else:
                removed_indices.append(i)

        if len(filtered) < 5:
            print(
                f"‚ö† Too many outliers ({len(removed_indices)}), keeping all samples")
            return embeddings

        print(
            f"‚úì Outlier removal: kept {len(filtered)}/{len(embeddings)} samples")
        if removed_indices:
            print(f"  Removed sample indices: {removed_indices}")

        return filtered

    # =====================================================
    def _calculate_quality_score(self, embeddings):
        """T√≠nh ƒëi·ªÉm ch·∫•t l∆∞·ª£ng c·ªßa t·∫≠p embeddings"""
        if len(embeddings) < 2:
            return 0.0

        # T√≠nh ƒë·ªô ph√¢n t√°n (variance) - cao h∆°n = ƒëa d·∫°ng h∆°n
        mean = np.mean(embeddings, axis=0)
        variances = []
        for emb in embeddings:
            dist = 1.0 - float(np.dot(emb, mean))
            variances.append(dist)

        avg_variance = np.mean(variances)
        quality_score = min(1.0, avg_variance / 0.2)  # Normalize to 0-1

        return quality_score

    # =====================================================
    def save(self, student_id, name):
        if not self.samples:
            print("‚ùå Kh√¥ng c√≥ m·∫´u ƒë·ªÉ l∆∞u")
            return False

        print(f"\n{'='*60}")
        print(f"üíæ Saving enrollment for: {name} ({student_id})")
        print(f"{'='*60}")

        # ===== Remove outliers =====
        embeddings = self._remove_outliers(self.samples)

        # ===== Calculate quality =====
        quality = self._calculate_quality_score(embeddings)
        print(f"üìä Quality score: {quality:.2%}")

        # ===== Mean + normalize =====
        mean_emb = np.mean(embeddings, axis=0)
        mean_emb /= (np.linalg.norm(mean_emb) + 1e-10)

        # Th·ªùi ƒëi·ªÉm hi·ªán t·∫°i
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # ===== Load existing database =====
        data = []
        if os.path.exists(self.db_path):
            try:
                with open(self.db_path, "rb") as f:
                    data = pickle.load(f)
                print(f"‚úì Loaded existing database ({len(data)} records)")
            except Exception as e:
                print(f"‚ö† Error loading database: {e}")
                data = []

        # ===== Update or append =====
        updated = False
        for i, item in enumerate(data):
            if item["id"] == student_id:
                # GI·ªÆ created_date c≈©
                record = {
                    "id": student_id,
                    "name": name,
                    "embedding": mean_emb,
                    "num_samples": len(embeddings),
                    "quality_score": quality,
                    "model": "buffalo_l",
                    "created_date": item.get("created_date", now)
                }
                data[i] = record
                updated = True
                print(f"‚úì Updated existing record for {student_id}")
                break

        if not updated:
            # Sinh vi√™n m·ªõi ‚Üí t·∫°o created_date
            record = {
                "id": student_id,
                "name": name,
                "embedding": mean_emb,
                "num_samples": len(embeddings),
                "quality_score": quality,
                "model": "buffalo_l",
                "created_date": now
            }
            data.append(record)
            print(f"‚úì Added new record for {student_id}")

        # ===== Save to file =====
        try:
            with open(self.db_path, "wb") as f:
                pickle.dump(data, f)
            print(f"‚úÖ SUCCESS!")
            print(f"   Student: {name} ({student_id})")
            print(f"   Samples: {len(embeddings)}/{len(self.samples)}")
            print(f"   Quality: {quality:.2%}")
            print(f"   Created: {record['created_date']}") # type: ignore
            print(f"   Location: {self.db_path}")
            print(f"{'='*60}\n")
        except Exception as e:
            print(f"‚ùå L·ªói l∆∞u embedding: {e}")
            return False

        # ===== Clear samples =====
        self.samples.clear()
        self.last_embedding = None

        return True

    # =====================================================
    def reset(self):
        self.samples.clear()
        self.last_embedding = None
        print("‚ôªÔ∏è  EnrollManager reset")
